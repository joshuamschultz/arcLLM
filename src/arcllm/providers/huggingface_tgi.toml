[provider]
api_format = "openai-chat"
base_url = "http://localhost:8080"
api_key_env = "TGI_API_KEY"
api_key_required = false
default_model = "tgi-model"
default_temperature = 0.7
vault_path = ""

[models.tgi-model]
context_window = 4096
max_output_tokens = 2048
supports_tools = true
supports_vision = false
supports_thinking = false
input_modalities = ["text"]
cost_input_per_1m = 0.0
cost_output_per_1m = 0.0
cost_cache_read_per_1m = 0.0
cost_cache_write_per_1m = 0.0
