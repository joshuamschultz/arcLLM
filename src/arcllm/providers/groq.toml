[provider]
api_format = "openai-chat"
base_url = "https://api.groq.com/openai"
api_key_env = "GROQ_API_KEY"
api_key_required = true
default_model = "llama-3.3-70b-versatile"
default_temperature = 0.7
vault_path = ""

[models."llama-3.3-70b-versatile"]
context_window = 128000
max_output_tokens = 32768
supports_tools = true
supports_vision = false
supports_thinking = false
input_modalities = ["text"]
cost_input_per_1m = 0.59
cost_output_per_1m = 0.79
cost_cache_read_per_1m = 0.0
cost_cache_write_per_1m = 0.0

[models."llama-3.1-8b-instant"]
context_window = 128000
max_output_tokens = 8192
supports_tools = true
supports_vision = false
supports_thinking = false
input_modalities = ["text"]
cost_input_per_1m = 0.05
cost_output_per_1m = 0.08
cost_cache_read_per_1m = 0.0
cost_cache_write_per_1m = 0.0

[models."mixtral-8x7b-32768"]
context_window = 32768
max_output_tokens = 4096
supports_tools = true
supports_vision = false
supports_thinking = false
input_modalities = ["text"]
cost_input_per_1m = 0.24
cost_output_per_1m = 0.24
cost_cache_read_per_1m = 0.0
cost_cache_write_per_1m = 0.0
