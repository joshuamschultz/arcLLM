{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArcLLM Step 1: Core Types & Exceptions\n",
    "\n",
    "This notebook walks through everything built in Step 1 — the **type layer** that forms the contract every other layer builds on.\n",
    "\n",
    "**What was built:**\n",
    "- Exception hierarchy (`ArcLLMError`, `ArcLLMParseError`, `ArcLLMConfigError`)\n",
    "- Content blocks (`TextBlock`, `ImageBlock`, `ToolUseBlock`, `ToolResultBlock`)\n",
    "- Discriminated union (`ContentBlock`)\n",
    "- `Message`, `Tool`, `ToolCall`, `Usage`, `LLMResponse`\n",
    "- `LLMProvider` abstract base class\n",
    "\n",
    "**Why it matters:** These types are the single source of truth. Every adapter, module, and agent interacts through them. Get these wrong, and everything downstream breaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, make sure arcllm is importable\n",
    "from arcllm import (\n",
    "    TextBlock, ImageBlock, ToolUseBlock, ToolResultBlock,\n",
    "    Message, Tool, ToolCall, Usage, LLMResponse, LLMProvider,\n",
    "    ArcLLMError, ArcLLMParseError, ArcLLMConfigError,\n",
    "    load_model,\n",
    ")\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Exception Hierarchy\n",
    "\n",
    "ArcLLM has a clean 3-class exception tree:\n",
    "\n",
    "```\n",
    "ArcLLMError (base — catch everything)\n",
    "├── ArcLLMParseError   (tool call JSON couldn't be parsed)\n",
    "└── ArcLLMConfigError  (config validation failed)\n",
    "```\n",
    "\n",
    "**Design decision:** Fail fast, fail loud. Every error attaches raw data so agents can log/debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ArcLLMError is the base — all ArcLLM exceptions inherit from it\n",
    "err = ArcLLMError(\"something went wrong\")\n",
    "print(f\"Type: {type(err).__name__}\")\n",
    "print(f\"Message: {err}\")\n",
    "print(f\"Is Exception? {isinstance(err, Exception)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ArcLLMParseError — when an LLM returns unparseable tool call arguments\n",
    "# It preserves the raw string AND the original error for debugging\n",
    "import json\n",
    "\n",
    "bad_json = '{\"broken json'\n",
    "try:\n",
    "    json.loads(bad_json)\n",
    "except json.JSONDecodeError as e:\n",
    "    parse_err = ArcLLMParseError(raw_string=bad_json, original_error=e)\n",
    "\n",
    "print(f\"Error message: {parse_err}\")\n",
    "print(f\"Raw string preserved: {parse_err.raw_string!r}\")\n",
    "print(f\"Original error type: {type(parse_err.original_error).__name__}\")\n",
    "print(f\"Is ArcLLMError? {isinstance(parse_err, ArcLLMError)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ArcLLMConfigError — raised when config validation fails\n",
    "config_err = ArcLLMConfigError(\"Missing API key env var\")\n",
    "print(f\"Message: {config_err}\")\n",
    "print(f\"Is ArcLLMError? {isinstance(config_err, ArcLLMError)}\")\n",
    "\n",
    "# You can catch ALL arcllm errors with one except clause:\n",
    "try:\n",
    "    raise ArcLLMParseError(\"bad\", ValueError(\"oops\"))\n",
    "except ArcLLMError as e:\n",
    "    print(f\"\\nCaught via base class: {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Content Blocks\n",
    "\n",
    "LLM messages aren't just text. They can contain images, tool calls, and tool results.\n",
    "\n",
    "ArcLLM models this with **4 content block types**, each tagged with a `type` field:\n",
    "\n",
    "| Block | `type` | Purpose |\n",
    "|-------|--------|---------|\n",
    "| `TextBlock` | `\"text\"` | Plain text content |\n",
    "| `ImageBlock` | `\"image\"` | Image data (base64 or URL) |\n",
    "| `ToolUseBlock` | `\"tool_use\"` | LLM wants to call a tool |\n",
    "| `ToolResultBlock` | `\"tool_result\"` | Result from executing a tool |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlock — the simplest content type\n",
    "text = TextBlock(text=\"Hello from Claude!\")\n",
    "print(f\"Type tag: {text.type!r}\")\n",
    "print(f\"Text: {text.text!r}\")\n",
    "print(f\"As dict: {text.model_dump()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageBlock — for vision-capable models\n",
    "image = ImageBlock(source=\"base64encodeddata...\", media_type=\"image/png\")\n",
    "print(f\"Type tag: {image.type!r}\")\n",
    "print(f\"Media type: {image.media_type}\")\n",
    "print(f\"As dict: {image.model_dump()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToolUseBlock — when the LLM wants to call a tool\n",
    "# This is the core of agentic behavior!\n",
    "tool_use = ToolUseBlock(\n",
    "    id=\"toolu_01abc\",\n",
    "    name=\"search_database\",\n",
    "    arguments={\"query\": \"arcllm config\", \"limit\": 10}\n",
    ")\n",
    "print(f\"Type tag: {tool_use.type!r}\")\n",
    "print(f\"Tool name: {tool_use.name}\")\n",
    "print(f\"Arguments: {tool_use.arguments}\")\n",
    "print(f\"Call ID: {tool_use.id}  (links to ToolResultBlock)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToolResultBlock — the agent's response after executing the tool\n",
    "# Simple case: string content\n",
    "result_simple = ToolResultBlock(\n",
    "    tool_use_id=\"toolu_01abc\",  # must match the ToolUseBlock.id\n",
    "    content=\"Found 3 matching records\"\n",
    ")\n",
    "print(f\"Type tag: {result_simple.type!r}\")\n",
    "print(f\"Links to: {result_simple.tool_use_id}\")\n",
    "print(f\"Content: {result_simple.content!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToolResultBlock can also contain nested ContentBlocks!\n",
    "# This is for rich results (text + images, multiple sections, etc.)\n",
    "result_rich = ToolResultBlock(\n",
    "    tool_use_id=\"toolu_01abc\",\n",
    "    content=[\n",
    "        TextBlock(text=\"Found 3 records:\"),\n",
    "        TextBlock(text=\"1. arcllm.config — TOML loader\"),\n",
    "        TextBlock(text=\"2. arcllm.types — Core types\"),\n",
    "    ]\n",
    ")\n",
    "print(f\"Content is a list: {type(result_rich.content).__name__}\")\n",
    "print(f\"Number of blocks: {len(result_rich.content)}\")\n",
    "for i, block in enumerate(result_rich.content):\n",
    "    print(f\"  [{i}] {type(block).__name__}: {block.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Discriminated Union\n",
    "\n",
    "`ContentBlock` is a **discriminated union** — Pydantic looks at the `type` field to decide which model to use.\n",
    "\n",
    "This means you can pass raw dicts with a `type` key and Pydantic auto-parses them into the right class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import TypeAdapter\n",
    "from arcllm.types import ContentBlock\n",
    "\n",
    "# Parse raw dicts — Pydantic checks the 'type' field automatically\n",
    "adapter = TypeAdapter(ContentBlock)\n",
    "\n",
    "parsed_text = adapter.validate_python({\"type\": \"text\", \"text\": \"hello\"})\n",
    "print(f\"Dict -> {type(parsed_text).__name__}: {parsed_text.text}\")\n",
    "\n",
    "parsed_tool = adapter.validate_python({\n",
    "    \"type\": \"tool_use\",\n",
    "    \"id\": \"c1\",\n",
    "    \"name\": \"search\",\n",
    "    \"arguments\": {}\n",
    "})\n",
    "print(f\"Dict -> {type(parsed_tool).__name__}: {parsed_tool.name}\")\n",
    "\n",
    "# Invalid type field will raise a ValidationError\n",
    "from pydantic import ValidationError\n",
    "try:\n",
    "    adapter.validate_python({\"type\": \"audio\", \"data\": \"...\"})\n",
    "except ValidationError as e:\n",
    "    print(f\"\\nInvalid type rejected: {e.error_count()} error(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Message\n",
    "\n",
    "A `Message` combines a **role** and **content**. The role is one of four literals:\n",
    "\n",
    "| Role | Who's talking | Typical content |\n",
    "|------|---------------|-----------------|\n",
    "| `\"system\"` | System prompt | Text instructions |\n",
    "| `\"user\"` | The human or agent | Text, images |\n",
    "| `\"assistant\"` | The LLM | Text, tool use blocks |\n",
    "| `\"tool\"` | Tool execution | Tool result blocks |\n",
    "\n",
    "Content can be a plain `str` OR a `list[ContentBlock]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple text message\n",
    "user_msg = Message(role=\"user\", content=\"What's the weather in Austin?\")\n",
    "print(f\"Role: {user_msg.role}\")\n",
    "print(f\"Content type: {type(user_msg.content).__name__}\")\n",
    "print(f\"Content: {user_msg.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-block assistant message (text + tool call)\n",
    "# This is what a real agentic response looks like\n",
    "assistant_msg = Message(\n",
    "    role=\"assistant\",\n",
    "    content=[\n",
    "        TextBlock(text=\"Let me check the weather for you.\"),\n",
    "        ToolUseBlock(\n",
    "            id=\"toolu_weather_1\",\n",
    "            name=\"get_weather\",\n",
    "            arguments={\"city\": \"Austin\", \"units\": \"fahrenheit\"}\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "print(f\"Role: {assistant_msg.role}\")\n",
    "print(f\"Content blocks: {len(assistant_msg.content)}\")\n",
    "for block in assistant_msg.content:\n",
    "    print(f\"  {type(block).__name__}: \", end=\"\")\n",
    "    if isinstance(block, TextBlock):\n",
    "        print(block.text)\n",
    "    elif isinstance(block, ToolUseBlock):\n",
    "        print(f\"{block.name}({block.arguments})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminated union works inside Message too — raw dicts auto-parse\n",
    "msg_from_dicts = Message(\n",
    "    role=\"assistant\",\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": \"thinking...\"},\n",
    "        {\"type\": \"tool_use\", \"id\": \"c1\", \"name\": \"search\", \"arguments\": {}},\n",
    "    ],\n",
    ")\n",
    "print(f\"Parsed from dicts:\")\n",
    "print(f\"  [0] {type(msg_from_dicts.content[0]).__name__}\")\n",
    "print(f\"  [1] {type(msg_from_dicts.content[1]).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invalid roles are rejected at construction time — fail fast!\n",
    "from pydantic import ValidationError\n",
    "\n",
    "try:\n",
    "    Message(role=\"admin\", content=\"hack the planet\")\n",
    "except ValidationError as e:\n",
    "    print(f\"Rejected! {e.error_count()} validation error(s):\")\n",
    "    for err in e.errors():\n",
    "        print(f\"  Field: {err['loc']}, Type: {err['type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge case: empty content list is allowed (some APIs use this)\n",
    "empty_msg = Message(role=\"user\", content=[])\n",
    "print(f\"Empty content list: {empty_msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Tool\n",
    "\n",
    "A `Tool` is the **definition** you send TO the LLM — \"here are tools you can use.\"\n",
    "\n",
    "The `parameters` field is raw JSON Schema (`dict[str, Any]`), kept loose intentionally so it matches what providers expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tool the LLM can call\n",
    "search_tool = Tool(\n",
    "    name=\"search_database\",\n",
    "    description=\"Search the internal knowledge base for relevant documents\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The search query\"\n",
    "            },\n",
    "            \"limit\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"Max results to return\",\n",
    "                \"default\": 10\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Tool name: {search_tool.name}\")\n",
    "print(f\"Description: {search_tool.description}\")\n",
    "print(f\"Parameters schema: {json.dumps(search_tool.parameters, indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. ToolCall\n",
    "\n",
    "A `ToolCall` is what the LLM returns — \"I want to call this tool with these arguments.\"\n",
    "\n",
    "Key difference from `ToolUseBlock`: ToolCall is a standalone object on `LLMResponse.tool_calls`. ToolUseBlock is a content block inside a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToolCall — what comes back from the LLM\n",
    "call = ToolCall(\n",
    "    id=\"toolu_01XYZ\",\n",
    "    name=\"search_database\",\n",
    "    arguments={\"query\": \"federal compliance\", \"limit\": 5}\n",
    ")\n",
    "print(f\"Call ID: {call.id}\")\n",
    "print(f\"Tool: {call.name}\")\n",
    "print(f\"Arguments (already parsed dict): {call.arguments}\")\n",
    "print(f\"\\nNote: arguments is always a dict, never a raw JSON string.\")\n",
    "print(f\"The adapter handles parsing. If it fails -> ArcLLMParseError.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Usage\n",
    "\n",
    "Every LLM response includes token usage. ArcLLM tracks:\n",
    "- Required: `input_tokens`, `output_tokens`, `total_tokens`\n",
    "- Optional: `cache_read_tokens`, `cache_write_tokens`, `reasoning_tokens`\n",
    "\n",
    "Optional fields are `None` when the provider doesn't report them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic usage (what most providers return)\n",
    "basic_usage = Usage(input_tokens=1500, output_tokens=300, total_tokens=1800)\n",
    "print(f\"Input:  {basic_usage.input_tokens:,} tokens\")\n",
    "print(f\"Output: {basic_usage.output_tokens:,} tokens\")\n",
    "print(f\"Total:  {basic_usage.total_tokens:,} tokens\")\n",
    "print(f\"Cache read:  {basic_usage.cache_read_tokens}  (None = not reported)\")\n",
    "print(f\"Cache write: {basic_usage.cache_write_tokens}  (None = not reported)\")\n",
    "print(f\"Reasoning:   {basic_usage.reasoning_tokens}  (None = not reported)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full usage with caching and reasoning (Anthropic-style)\n",
    "full_usage = Usage(\n",
    "    input_tokens=1500,\n",
    "    output_tokens=300,\n",
    "    total_tokens=1800,\n",
    "    cache_read_tokens=1200,   # tokens read from prompt cache\n",
    "    cache_write_tokens=300,   # tokens written to prompt cache\n",
    "    reasoning_tokens=150,     # tokens used for extended thinking\n",
    ")\n",
    "print(f\"Cache read:  {full_usage.cache_read_tokens:,} tokens\")\n",
    "print(f\"Cache write: {full_usage.cache_write_tokens:,} tokens\")\n",
    "print(f\"Reasoning:   {full_usage.reasoning_tokens:,} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero tokens is valid (edge case, but should not crash)\n",
    "zero_usage = Usage(input_tokens=0, output_tokens=0, total_tokens=0)\n",
    "print(f\"Zero usage valid: input={zero_usage.input_tokens}, total={zero_usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. LLMResponse\n",
    "\n",
    "The **normalized response** from any provider. This is the key abstraction — regardless of whether you're calling Anthropic, OpenAI, or Ollama, you get the same response shape.\n",
    "\n",
    "| Field | Type | Purpose |\n",
    "|-------|------|---------|\n",
    "| `content` | `str \\| None` | Text response (None during pure tool calls) |\n",
    "| `tool_calls` | `list[ToolCall]` | Tools the LLM wants to execute |\n",
    "| `usage` | `Usage` | Token counts |\n",
    "| `model` | `str` | Which model responded |\n",
    "| `stop_reason` | `str` | Why the LLM stopped (`\"end_turn\"`, `\"tool_use\"`, etc.) |\n",
    "| `thinking` | `str \\| None` | Extended thinking content (if supported) |\n",
    "| `raw` | `Any` | Raw provider response (for debugging only) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 1: Normal text response (end of conversation)\n",
    "text_response = LLMResponse(\n",
    "    content=\"The weather in Austin is 75F and sunny.\",\n",
    "    usage=Usage(input_tokens=500, output_tokens=20, total_tokens=520),\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    stop_reason=\"end_turn\",\n",
    ")\n",
    "print(f\"Content: {text_response.content}\")\n",
    "print(f\"Stop reason: {text_response.stop_reason}\")\n",
    "print(f\"Tool calls: {text_response.tool_calls}  (empty = no tools needed)\")\n",
    "print(f\"Model: {text_response.model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 2: Tool use response (agent loop continues)\n",
    "tool_response = LLMResponse(\n",
    "    content=None,  # No text when doing pure tool calls\n",
    "    tool_calls=[\n",
    "        ToolCall(id=\"c1\", name=\"get_weather\", arguments={\"city\": \"Austin\"}),\n",
    "        ToolCall(id=\"c2\", name=\"get_time\", arguments={\"timezone\": \"CST\"}),\n",
    "    ],\n",
    "    usage=Usage(input_tokens=800, output_tokens=50, total_tokens=850),\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    stop_reason=\"tool_use\",\n",
    ")\n",
    "print(f\"Content: {tool_response.content}  (None = LLM wants to use tools)\")\n",
    "print(f\"Stop reason: {tool_response.stop_reason}\")\n",
    "print(f\"Tool calls: {len(tool_response.tool_calls)}\")\n",
    "for tc in tool_response.tool_calls:\n",
    "    print(f\"  -> {tc.name}({tc.arguments})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 3: Mixed response (text + tool calls)\n",
    "# Some models return text alongside tool calls\n",
    "mixed_response = LLMResponse(\n",
    "    content=\"Let me look that up for you.\",\n",
    "    tool_calls=[\n",
    "        ToolCall(id=\"c1\", name=\"search\", arguments={\"q\": \"test\"})\n",
    "    ],\n",
    "    usage=Usage(input_tokens=50, output_tokens=30, total_tokens=80),\n",
    "    model=\"test-model\",\n",
    "    stop_reason=\"tool_use\",\n",
    ")\n",
    "print(f\"Has content AND tool calls:\")\n",
    "print(f\"  Content: {mixed_response.content!r}\")\n",
    "print(f\"  Tool calls: {len(mixed_response.tool_calls)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The agentic loop pattern: check stop_reason to decide what to do\n",
    "def show_agent_decision(response: LLMResponse):\n",
    "    \"\"\"Simulate what an agent does with an LLMResponse.\"\"\"\n",
    "    if response.stop_reason == \"end_turn\":\n",
    "        print(f\"DONE -> Final answer: {response.content}\")\n",
    "    elif response.stop_reason == \"tool_use\":\n",
    "        print(f\"TOOL LOOP -> Execute {len(response.tool_calls)} tool(s), then call complete() again\")\n",
    "        for tc in response.tool_calls:\n",
    "            print(f\"  Execute: {tc.name}({tc.arguments})\")\n",
    "    else:\n",
    "        print(f\"UNKNOWN stop_reason: {response.stop_reason}\")\n",
    "\n",
    "print(\"--- Text response ---\")\n",
    "show_agent_decision(text_response)\n",
    "\n",
    "print(\"\\n--- Tool response ---\")\n",
    "show_agent_decision(tool_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. LLMProvider (Abstract Base Class)\n",
    "\n",
    "Every adapter (Anthropic, OpenAI, Ollama) must implement this interface.\n",
    "\n",
    "It defines exactly two methods:\n",
    "- `complete()` — send messages + tools, get back an `LLMResponse`\n",
    "- `validate_config()` — check that the provider is properly configured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You CANNOT instantiate LLMProvider directly — it's abstract\n",
    "try:\n",
    "    provider = LLMProvider()\n",
    "except TypeError as e:\n",
    "    print(f\"Cannot instantiate ABC: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But you CAN create a concrete subclass\n",
    "class MockProvider(LLMProvider):\n",
    "    name = \"mock\"\n",
    "\n",
    "    async def complete(self, messages, tools=None, **kwargs):\n",
    "        return LLMResponse(\n",
    "            content=\"I'm a mock response!\",\n",
    "            usage=Usage(input_tokens=10, output_tokens=5, total_tokens=15),\n",
    "            model=\"mock-v1\",\n",
    "            stop_reason=\"end_turn\",\n",
    "        )\n",
    "\n",
    "    def validate_config(self):\n",
    "        return True\n",
    "\n",
    "mock = MockProvider()\n",
    "print(f\"Provider name: {mock.name}\")\n",
    "print(f\"Config valid: {mock.validate_config()}\")\n",
    "print(f\"Is LLMProvider? {isinstance(mock, LLMProvider)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the mock provider (async)\n",
    "import asyncio\n",
    "\n",
    "async def demo_complete():\n",
    "    messages = [\n",
    "        Message(role=\"user\", content=\"Hello!\")\n",
    "    ]\n",
    "    response = await mock.complete(messages)\n",
    "    print(f\"Response: {response.content}\")\n",
    "    print(f\"Model: {response.model}\")\n",
    "    print(f\"Usage: {response.usage.total_tokens} tokens\")\n",
    "\n",
    "await demo_complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Serialization\n",
    "\n",
    "All types are Pydantic models, so they serialize cleanly to/from dicts and JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize to dict\n",
    "msg = Message(\n",
    "    role=\"assistant\",\n",
    "    content=[\n",
    "        TextBlock(text=\"Here's a tool call\"),\n",
    "        ToolUseBlock(id=\"c1\", name=\"calc\", arguments={\"expr\": \"2+2\"}),\n",
    "    ]\n",
    ")\n",
    "\n",
    "as_dict = msg.model_dump()\n",
    "print(f\"As dict:\\n{json.dumps(as_dict, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize to JSON string\n",
    "as_json = msg.model_dump_json(indent=2)\n",
    "print(f\"As JSON:\\n{as_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialize from dict\n",
    "reconstructed = Message.model_validate(as_dict)\n",
    "print(f\"Reconstructed: role={reconstructed.role}, blocks={len(reconstructed.content)}\")\n",
    "print(f\"Same data? {reconstructed == msg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. load_model() Placeholder\n",
    "\n",
    "`load_model()` is the public API entry point. It's defined but not implemented yet (Step 6).\n",
    "\n",
    "This is intentional — the type layer comes first, then config, then adapters, THEN the registry that ties it together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model = load_model(\"anthropic\")\n",
    "except NotImplementedError as e:\n",
    "    print(f\"Expected: {e}\")\n",
    "    print(f\"\\nThis will work after Step 6 (Provider Registry).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "Step 1 built the **foundation contract**:\n",
    "\n",
    "```\n",
    "exceptions.py  ->  ArcLLMError, ArcLLMParseError, ArcLLMConfigError\n",
    "types.py       ->  ContentBlock variants, Message, Tool, ToolCall, Usage, LLMResponse, LLMProvider\n",
    "__init__.py    ->  Public API surface (all exports + load_model placeholder)\n",
    "```\n",
    "\n",
    "**Key design decisions:**\n",
    "- Pydantic v2 for type safety and validation\n",
    "- Discriminated union on `type` field for content blocks\n",
    "- `str | list[ContentBlock]` for message content (flexibility)\n",
    "- `dict[str, Any]` for tool parameters (raw JSON Schema, no over-abstraction)\n",
    "- Arguments always parsed to dict (adapter's job, not the type's)\n",
    "- ABC for providers (enforces interface contract)\n",
    "- Fail-fast exceptions with raw data attached"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}