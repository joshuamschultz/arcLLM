{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10 — Audit Trail Module\n",
    "\n",
    "**What we built**: An `AuditModule` that logs structured audit metadata per `invoke()` call — PII-safe by default.\n",
    "\n",
    "**Why it matters**: Federal compliance (NIST 800-53 AU-3) requires an audit trail for every LLM interaction. Thousands of autonomous agents need observable interactions without creating new PII exposure. The audit module captures *what happened* (provider, model, message count, tool calls) without capturing *what was said* (message content, response content) — unless explicitly opted in.\n",
    "\n",
    "**Key decisions**:\n",
    "- **D-070**: Structured logging (same pattern as telemetry — parseable by log aggregation systems)\n",
    "- **D-072**: Fields: provider, model, message_count, stop_reason, tools_provided (conditional), tool_calls (conditional), content_length\n",
    "- **D-073**: No raw content by default — PII safety for federal environments\n",
    "- **D-074**: `include_messages` and `include_response` — explicit opt-in, logged at DEBUG level (double opt-in)\n",
    "\n",
    "**Stack position**: `Telemetry → Audit → Retry → Fallback → RateLimit → Adapter`\n",
    "\n",
    "**New shared infrastructure**: `_logging.py` — `log_structured()`, `validate_log_level()`, `_sanitize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: ensure arcllm is importable\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..', 'src')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. What Gets Logged (Default — PII-Safe)\n",
    "\n",
    "Every `invoke()` call produces one structured audit log line:\n",
    "\n",
    "```\n",
    "INFO  Audit | provider=anthropic model=claude-sonnet-4-20250514 message_count=3\n",
    "              stop_reason=end_turn content_length=142\n",
    "```\n",
    "\n",
    "**Always present**: provider, model, message_count, stop_reason, content_length\n",
    "\n",
    "**Conditional**: `tools_provided` (only when tools arg is not None), `tool_calls` (only when response has tool_calls)\n",
    "\n",
    "**Never logged by default**: Raw message content, raw response content (PII safety)\n",
    "\n",
    "### Audit vs. Telemetry — Different Concerns\n",
    "\n",
    "| | Telemetry | Audit |\n",
    "|---|-----------|-------|\n",
    "| **Purpose** | Performance + cost | Compliance + debugging |\n",
    "| **Key fields** | duration_ms, tokens, cost_usd | message_count, tools, content_length |\n",
    "| **Overlap** | provider, model, stop_reason | provider, model, stop_reason |\n",
    "| **PII risk** | None (only numbers) | Protected (content opt-in) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Constructing AuditModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import AsyncMock, MagicMock\n",
    "from arcllm.modules.audit import AuditModule\n",
    "from arcllm.types import LLMProvider, LLMResponse, Message, Tool, ToolCall, Usage\n",
    "\n",
    "# Create a mock inner adapter\n",
    "inner = MagicMock(spec=LLMProvider)\n",
    "inner.name = \"anthropic\"\n",
    "inner.model_name = \"claude-sonnet-4-20250514\"\n",
    "inner.invoke = AsyncMock(return_value=LLMResponse(\n",
    "    content=\"Hello there!\",\n",
    "    usage=Usage(input_tokens=100, output_tokens=50, total_tokens=150),\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    stop_reason=\"end_turn\",\n",
    "))\n",
    "\n",
    "# Default config — PII-safe\n",
    "module = AuditModule({}, inner)\n",
    "\n",
    "print(f\"Module type:        {type(module).__name__}\")\n",
    "print(f\"Provider (inner):   {module.name}\")\n",
    "print(f\"Model (inner):      {module.model_name}\")\n",
    "print(f\"Include messages:   {module._include_messages}\")\n",
    "print(f\"Include response:   {module._include_response}\")\n",
    "print(f\"Log level:          {module._log_level} (20=INFO)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Basic Audit Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set up logging to see output\n",
    "handler = logging.StreamHandler()\n",
    "handler.setFormatter(logging.Formatter(\"%(levelname)s %(name)s: %(message)s\"))\n",
    "audit_logger = logging.getLogger(\"arcllm.modules.audit\")\n",
    "audit_logger.addHandler(handler)\n",
    "audit_logger.setLevel(logging.INFO)\n",
    "\n",
    "messages = [\n",
    "    Message(role=\"system\", content=\"You are a helpful assistant.\"),\n",
    "    Message(role=\"user\", content=\"What is 2+2?\"),\n",
    "]\n",
    "\n",
    "result = await module.invoke(messages)\n",
    "\n",
    "audit_logger.removeHandler(handler)\n",
    "\n",
    "print(f\"\\nResponse: {result.content}\")\n",
    "print(f\"\\nNotice: NO message content or response content in the audit log above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log shows:\n",
    "- `provider=anthropic` — which provider\n",
    "- `model=claude-sonnet-4-20250514` — which model\n",
    "- `message_count=2` — how many messages sent\n",
    "- `stop_reason=end_turn` — why the model stopped\n",
    "- `content_length=12` — response length in chars (`len(\"Hello there!\")` = 12)\n",
    "\n",
    "**Not logged**: \"You are a helpful assistant\", \"What is 2+2?\", \"Hello there!\" (PII-safe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Conditional Fields: Tools and Tool Calls\n",
    "\n",
    "Tool-related fields appear **only when relevant** — reducing log noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response WITH tool calls\n",
    "tool_response = LLMResponse(\n",
    "    content=None,\n",
    "    tool_calls=[\n",
    "        ToolCall(id=\"call_1\", name=\"search\", arguments={\"query\": \"test\"}),\n",
    "        ToolCall(id=\"call_2\", name=\"calc\", arguments={\"expr\": \"1+1\"}),\n",
    "    ],\n",
    "    usage=Usage(input_tokens=20, output_tokens=10, total_tokens=30),\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    stop_reason=\"tool_use\",\n",
    ")\n",
    "\n",
    "# Tools provided to the model\n",
    "tools = [\n",
    "    Tool(name=\"search\", description=\"Search the web\", parameters={\"type\": \"object\"}),\n",
    "]\n",
    "\n",
    "inner_tools = MagicMock(spec=LLMProvider)\n",
    "inner_tools.name = \"anthropic\"\n",
    "inner_tools.invoke = AsyncMock(return_value=tool_response)\n",
    "mod_tools = AuditModule({}, inner_tools)\n",
    "\n",
    "audit_logger.addHandler(handler)\n",
    "audit_logger.setLevel(logging.INFO)\n",
    "\n",
    "print(\"=== With tools and tool_calls ===\")\n",
    "await mod_tools.invoke(messages, tools=tools)\n",
    "\n",
    "audit_logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without tools — fields omitted entirely\n",
    "inner_no_tools = MagicMock(spec=LLMProvider)\n",
    "inner_no_tools.name = \"anthropic\"\n",
    "inner_no_tools.invoke = AsyncMock(return_value=LLMResponse(\n",
    "    content=\"Just text.\",\n",
    "    usage=Usage(input_tokens=10, output_tokens=5, total_tokens=15),\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    stop_reason=\"end_turn\",\n",
    "))\n",
    "mod_no_tools = AuditModule({}, inner_no_tools)\n",
    "\n",
    "audit_logger.addHandler(handler)\n",
    "audit_logger.setLevel(logging.INFO)\n",
    "\n",
    "print(\"=== Without tools (fields omitted) ===\")\n",
    "await mod_no_tools.invoke(messages)\n",
    "\n",
    "audit_logger.removeHandler(handler)\n",
    "print(\"\\nNotice: 'tools_provided' and 'tool_calls' are absent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conditional logic uses `None` omission in `log_structured()`:\n",
    "```python\n",
    "tools_provided=len(tools) if tools is not None else None,  # None → omitted\n",
    "tool_calls=len(response.tool_calls) if response.tool_calls else None,  # [] or None → omitted\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. PII Safety — The Default\n",
    "\n",
    "The core compliance requirement: audit trail exists, but doesn't create new PII exposure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "# Capture ALL log output (even DEBUG)\n",
    "stream = io.StringIO()\n",
    "debug_handler = logging.StreamHandler(stream)\n",
    "debug_handler.setLevel(logging.DEBUG)\n",
    "audit_logger.addHandler(debug_handler)\n",
    "audit_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Messages with sensitive content\n",
    "sensitive_messages = [\n",
    "    Message(role=\"system\", content=\"You are a medical assistant.\"),\n",
    "    Message(role=\"user\", content=\"Patient John Smith, SSN 123-45-6789, has diabetes.\"),\n",
    "]\n",
    "\n",
    "sensitive_response = LLMResponse(\n",
    "    content=\"Based on the patient's condition, I recommend...\",\n",
    "    usage=Usage(input_tokens=50, output_tokens=30, total_tokens=80),\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    stop_reason=\"end_turn\",\n",
    ")\n",
    "\n",
    "inner_pii = MagicMock(spec=LLMProvider)\n",
    "inner_pii.name = \"anthropic\"\n",
    "inner_pii.invoke = AsyncMock(return_value=sensitive_response)\n",
    "\n",
    "# Default module — PII safe\n",
    "mod_safe = AuditModule({}, inner_pii)\n",
    "await mod_safe.invoke(sensitive_messages)\n",
    "\n",
    "log_output = stream.getvalue()\n",
    "audit_logger.removeHandler(debug_handler)\n",
    "\n",
    "# Verify PII is NOT in the log\n",
    "print(\"=== PII Safety Check ===\")\n",
    "print(f\"Log output: {log_output.strip()}\")\n",
    "print()\n",
    "print(f\"Contains 'John Smith':     {'John Smith' in log_output}\")\n",
    "print(f\"Contains 'SSN':            {'SSN' in log_output}\")\n",
    "print(f\"Contains '123-45-6789':    {'123-45-6789' in log_output}\")\n",
    "print(f\"Contains 'diabetes':       {'diabetes' in log_output}\")\n",
    "print(f\"Contains 'recommend':      {'recommend' in log_output}\")\n",
    "print(f\"Contains 'message_count':  {'message_count' in log_output}\")\n",
    "print(f\"Contains 'content_length': {'content_length' in log_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The audit log tells you *that* 2 messages were sent and the response was ~48 chars, without revealing *what* was in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Opt-In Content Logging (Double Opt-In)\n",
    "\n",
    "For dev/staging environments where logging raw content is acceptable, content logging requires **two conditions**:\n",
    "1. Config flag (`include_messages=True` / `include_response=True`)\n",
    "2. Logger at DEBUG level\n",
    "\n",
    "This \"double opt-in\" prevents accidental PII exposure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content logging with include_messages + include_response\n",
    "inner_content = MagicMock(spec=LLMProvider)\n",
    "inner_content.name = \"anthropic\"\n",
    "inner_content.invoke = AsyncMock(return_value=LLMResponse(\n",
    "    content=\"Hello there!\",\n",
    "    usage=Usage(input_tokens=10, output_tokens=5, total_tokens=15),\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    stop_reason=\"end_turn\",\n",
    "))\n",
    "\n",
    "mod_content = AuditModule(\n",
    "    {\"include_messages\": True, \"include_response\": True},\n",
    "    inner_content,\n",
    ")\n",
    "\n",
    "# Test 1: At INFO level — content NOT logged (second condition fails)\n",
    "stream1 = io.StringIO()\n",
    "h1 = logging.StreamHandler(stream1)\n",
    "h1.setLevel(logging.INFO)\n",
    "audit_logger.addHandler(h1)\n",
    "audit_logger.setLevel(logging.INFO)\n",
    "\n",
    "print(\"=== At INFO (content hidden despite include_* = True) ===\")\n",
    "await mod_content.invoke(messages)\n",
    "log1 = stream1.getvalue()\n",
    "print(f\"Contains message content: {'You are a helpful' in log1}\")\n",
    "print(f\"Contains response content: {'Hello there' in log1}\")\n",
    "audit_logger.removeHandler(h1)\n",
    "\n",
    "# Test 2: At DEBUG level — content IS logged (both conditions met)\n",
    "stream2 = io.StringIO()\n",
    "h2 = logging.StreamHandler(stream2)\n",
    "h2.setLevel(logging.DEBUG)\n",
    "audit_logger.addHandler(h2)\n",
    "audit_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "print(\"\\n=== At DEBUG (content visible) ===\")\n",
    "await mod_content.invoke(messages)\n",
    "log2 = stream2.getvalue()\n",
    "print(f\"Contains message content: {'helpful' in log2}\")\n",
    "print(f\"Contains response content: {'Hello there' in log2}\")\n",
    "audit_logger.removeHandler(h2)\n",
    "audit_logger.setLevel(logging.WARNING)  # Reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation:\n",
    "```python\n",
    "if self._include_messages and logger.isEnabledFor(logging.DEBUG):\n",
    "    logger.debug(\"Audit messages | %s\", _sanitize(str(messages)))\n",
    "if self._include_response and logger.isEnabledFor(logging.DEBUG):\n",
    "    logger.debug(\"Audit response | %s\", _sanitize(str(response.content)))\n",
    "```\n",
    "\n",
    "The `isEnabledFor()` guard prevents expensive string building when DEBUG is disabled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. The Shared `_logging.py` Helper\n",
    "\n",
    "A DRY extraction created during code review — shared by both TelemetryModule and AuditModule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcllm.modules._logging import log_structured, validate_log_level, _sanitize\n",
    "\n",
    "print(\"=== _sanitize() — prevents log injection ===\")\n",
    "print(f\"  Clean:     {repr(_sanitize('normal-model'))}\")\n",
    "print(f\"  Newline:   {repr(_sanitize('evil\\nINJECTED'))}\")\n",
    "print(f\"  CR:        {repr(_sanitize('evil\\rINJECTED'))}\")\n",
    "print(f\"  Tab:       {repr(_sanitize('evil\\tINJECTED'))}\")\n",
    "print(f\"  Non-str:   {repr(_sanitize(42))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== validate_log_level() — shared validation ===\")\n",
    "print(f\"  Default:    {validate_log_level({})} (INFO=20)\")\n",
    "print(f\"  Explicit:   {validate_log_level({'log_level': 'DEBUG'})} (DEBUG=10)\")\n",
    "print(f\"  Custom default: {validate_log_level({}, default='WARNING')} (WARNING=30)\")\n",
    "\n",
    "from arcllm.exceptions import ArcLLMConfigError\n",
    "try:\n",
    "    validate_log_level({\"log_level\": \"NOPE\"})\n",
    "except ArcLLMConfigError as e:\n",
    "    print(f\"  Invalid:    {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_structured() — the core helper\n",
    "test_logger = logging.getLogger(\"demo.structured\")\n",
    "h = logging.StreamHandler()\n",
    "h.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\n",
    "test_logger.addHandler(h)\n",
    "test_logger.setLevel(logging.INFO)\n",
    "\n",
    "print(\"=== log_structured() features ===\")\n",
    "print()\n",
    "\n",
    "# None values omitted\n",
    "print(\"1. None values omitted:\")\n",
    "log_structured(test_logger, logging.INFO, \"Test\",\n",
    "    present=\"yes\", missing=None, count=42)\n",
    "\n",
    "# Floats formatted to 6 decimals\n",
    "print(\"\\n2. Float formatting (6 decimals):\")\n",
    "log_structured(test_logger, logging.INFO, \"Test\",\n",
    "    cost_usd=0.00105)\n",
    "\n",
    "# Strings sanitized\n",
    "print(\"\\n3. String sanitization:\")\n",
    "log_structured(test_logger, logging.INFO, \"Test\",\n",
    "    model=\"evil\\nINJECTED\")\n",
    "\n",
    "# Level gating (no output)\n",
    "print(\"\\n4. Level gating (DEBUG at INFO level → silent):\")\n",
    "log_structured(test_logger, logging.DEBUG, \"Test\",\n",
    "    should_not=\"appear\")\n",
    "print(\"   (nothing above — level too low)\")\n",
    "\n",
    "test_logger.removeHandler(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Config Validation\n",
    "\n",
    "AuditModule validates config keys **strictly** — catches typos at construction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcllm.modules.audit import _VALID_CONFIG_KEYS\n",
    "\n",
    "inner = MagicMock(spec=LLMProvider)\n",
    "inner.name = \"test\"\n",
    "\n",
    "print(f\"Valid config keys: {sorted(_VALID_CONFIG_KEYS - {'enabled'})}\")\n",
    "print()\n",
    "\n",
    "# Typo caught at construction\n",
    "try:\n",
    "    AuditModule({\"include_mesages\": True}, inner)  # Missing 's'\n",
    "except ArcLLMConfigError as e:\n",
    "    print(f\"Typo caught: {e}\")\n",
    "\n",
    "# Invalid log level\n",
    "try:\n",
    "    AuditModule({\"log_level\": \"NOPE\"}, inner)\n",
    "except ArcLLMConfigError as e:\n",
    "    print(f\"\\nBad level:  {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `_VALID_CONFIG_KEYS` pattern was applied after code review — prevents silent misconfiguration where a typo'd key is silently ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Content Length Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text response → len(content)\n",
    "text_resp = LLMResponse(\n",
    "    content=\"Hello there!\",  # 12 chars\n",
    "    usage=Usage(input_tokens=10, output_tokens=5, total_tokens=15),\n",
    "    model=\"test\", stop_reason=\"end_turn\",\n",
    ")\n",
    "\n",
    "# Tool call response → content is None → length 0\n",
    "tool_resp = LLMResponse(\n",
    "    content=None,\n",
    "    tool_calls=[ToolCall(id=\"1\", name=\"search\", arguments={\"q\": \"test\"})],\n",
    "    usage=Usage(input_tokens=10, output_tokens=5, total_tokens=15),\n",
    "    model=\"test\", stop_reason=\"tool_use\",\n",
    ")\n",
    "\n",
    "print(f\"Text response: content_length = {len(text_resp.content or '')}\")\n",
    "print(f\"Tool response: content_length = {len(tool_resp.content or '')}\")\n",
    "print()\n",
    "print(\"Formula: len(response.content) if response.content else 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Log Injection Prevention\n",
    "\n",
    "The `_sanitize()` function escapes control characters that could corrupt structured logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model name with injection attempt\n",
    "injected_response = LLMResponse(\n",
    "    content=\"ok\",\n",
    "    usage=Usage(input_tokens=10, output_tokens=5, total_tokens=15),\n",
    "    model=\"gpt-4\\nINJECTED LOG LINE\",  # Newline injection\n",
    "    stop_reason=\"end_turn\",\n",
    ")\n",
    "\n",
    "inner_inject = MagicMock(spec=LLMProvider)\n",
    "inner_inject.name = \"test\"\n",
    "inner_inject.invoke = AsyncMock(return_value=injected_response)\n",
    "mod_inject = AuditModule({}, inner_inject)\n",
    "\n",
    "stream = io.StringIO()\n",
    "h = logging.StreamHandler(stream)\n",
    "audit_logger.addHandler(h)\n",
    "audit_logger.setLevel(logging.INFO)\n",
    "\n",
    "await mod_inject.invoke([Message(role=\"user\", content=\"hi\")])\n",
    "\n",
    "log_output = stream.getvalue()\n",
    "audit_logger.removeHandler(h)\n",
    "audit_logger.setLevel(logging.WARNING)\n",
    "\n",
    "print(f\"Log output: {repr(log_output.strip())}\")\n",
    "print(f\"\\nNewline escaped: {'\\\\n' in log_output}\")\n",
    "print(\"The injected log line is part of the model= field, not a separate line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Content Logging Sanitization\n",
    "\n",
    "Even when content logging is opted in, the output is sanitized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response with control characters in content\n",
    "evil_response = LLMResponse(\n",
    "    content=\"line1\\nline2\\rline3\\tend\",\n",
    "    usage=Usage(input_tokens=10, output_tokens=5, total_tokens=15),\n",
    "    model=\"test\",\n",
    "    stop_reason=\"end_turn\",\n",
    ")\n",
    "\n",
    "inner_evil = MagicMock(spec=LLMProvider)\n",
    "inner_evil.name = \"test\"\n",
    "inner_evil.invoke = AsyncMock(return_value=evil_response)\n",
    "mod_evil = AuditModule({\"include_response\": True}, inner_evil)\n",
    "\n",
    "stream = io.StringIO()\n",
    "h = logging.StreamHandler(stream)\n",
    "h.setLevel(logging.DEBUG)\n",
    "audit_logger.addHandler(h)\n",
    "audit_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "await mod_evil.invoke([Message(role=\"user\", content=\"hi\")])\n",
    "\n",
    "log_output = stream.getvalue()\n",
    "audit_logger.removeHandler(h)\n",
    "audit_logger.setLevel(logging.WARNING)\n",
    "\n",
    "print(\"Control chars in opt-in content are escaped:\")\n",
    "for line in log_output.strip().split('\\n'):\n",
    "    if 'response' in line.lower():\n",
    "        print(f\"  {line.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Exception Propagation\n",
    "\n",
    "AuditModule never swallows exceptions — they propagate to the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_fail = MagicMock(spec=LLMProvider)\n",
    "inner_fail.name = \"test\"\n",
    "inner_fail.invoke = AsyncMock(side_effect=RuntimeError(\"provider failure\"))\n",
    "mod_fail = AuditModule({}, inner_fail)\n",
    "\n",
    "try:\n",
    "    await mod_fail.invoke([Message(role=\"user\", content=\"hi\")])\n",
    "except RuntimeError as e:\n",
    "    print(f\"Exception propagated: {e}\")\n",
    "    print(\"Audit doesn't swallow errors — agent sees the failure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 13. Registry Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcllm.registry import load_model, clear_cache\n",
    "\n",
    "os.environ.setdefault(\"ANTHROPIC_API_KEY\", \"test-key\")\n",
    "os.environ.setdefault(\"OPENAI_API_KEY\", \"test-key\")\n",
    "clear_cache()\n",
    "\n",
    "# Enable audit\n",
    "model = load_model(\"anthropic\", audit=True)\n",
    "print(f\"Type: {type(model).__name__}\")\n",
    "print(f\"Inner: {type(model._inner).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "\n",
    "# Audit with content opt-in\n",
    "model = load_model(\"anthropic\", audit={\"include_messages\": True})\n",
    "print(f\"Type: {type(model).__name__}\")\n",
    "print(f\"Include messages: {model._include_messages}\")\n",
    "print(f\"Include response: {model._include_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "\n",
    "# Full 6-layer stack\n",
    "model = load_model(\n",
    "    \"anthropic\",\n",
    "    telemetry=True,\n",
    "    audit=True,\n",
    "    retry=True,\n",
    "    fallback=True,\n",
    "    rate_limit=True,\n",
    ")\n",
    "\n",
    "# Walk the stack\n",
    "layer = model\n",
    "depth = 0\n",
    "while hasattr(layer, '_inner'):\n",
    "    indent = \"  \" * depth\n",
    "    print(f\"{indent}{type(layer).__name__}\")\n",
    "    layer = layer._inner\n",
    "    depth += 1\n",
    "print(f\"{'  ' * depth}{type(layer).__name__}\")\n",
    "\n",
    "print(f\"\\n6 layers total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Audit sits between Telemetry and Retry:\n",
    "\n",
    "```\n",
    "Telemetry (wall-clock + cost — outermost)\n",
    "  └─ Audit (compliance metadata — sees retried/fallback'd result)\n",
    "      └─ Retry (may retry multiple times)\n",
    "          └─ Fallback (may switch provider)\n",
    "              └─ RateLimit (may wait for token)\n",
    "                  └─ Adapter (HTTP call)\n",
    "```\n",
    "\n",
    "Audit logs the **final** result the agent receives, not intermediate retry attempts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 14. Implementation Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "print(\"=== AuditModule.invoke ===\")\n",
    "print(inspect.getsource(AuditModule.invoke))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== AuditModule.__init__ ===\")\n",
    "print(inspect.getsource(AuditModule.__init__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== log_structured() ===\")\n",
    "print(inspect.getsource(log_structured))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 15. Live API Call with Audit\n",
    "\n",
    "Real Anthropic API call with `audit=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(os.path.join(os.getcwd(), '..', '.env'))\n",
    "\n",
    "has_key = bool(os.environ.get(\"ANTHROPIC_API_KEY\")) and os.environ.get(\"ANTHROPIC_API_KEY\") != \"test-key\"\n",
    "print(f\"Anthropic API key: {'found' if has_key else 'not found (skip live tests)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_key:\n",
    "    clear_cache()\n",
    "    \n",
    "    # Set up logging\n",
    "    h = logging.StreamHandler()\n",
    "    h.setFormatter(logging.Formatter(\"%(levelname)s %(name)s: %(message)s\"))\n",
    "    audit_logger = logging.getLogger(\"arcllm.modules.audit\")\n",
    "    audit_logger.addHandler(h)\n",
    "    audit_logger.setLevel(logging.INFO)\n",
    "    \n",
    "    model = load_model(\"anthropic\", audit=True)\n",
    "    print(f\"Stack: {type(model).__name__}({type(model._inner).__name__})\")\n",
    "    print()\n",
    "    \n",
    "    response = await model.invoke([\n",
    "        Message(role=\"system\", content=\"You are a helpful assistant.\"),\n",
    "        Message(role=\"user\", content=\"What is 2+2? Just the number.\"),\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\nResponse: {response.content}\")\n",
    "    print(\"\\nNotice: audit log shows message_count=2 but NO message content\")\n",
    "    \n",
    "    audit_logger.removeHandler(h)\n",
    "    await model._inner.close()\n",
    "else:\n",
    "    print(\"Skipped — no API key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_key:\n",
    "    clear_cache()\n",
    "    \n",
    "    # Audit + Telemetry together — both log independently\n",
    "    h = logging.StreamHandler()\n",
    "    h.setFormatter(logging.Formatter(\"%(levelname)s %(name)s: %(message)s\"))\n",
    "    \n",
    "    for logger_name in [\"arcllm.modules.audit\", \"arcllm.modules.telemetry\"]:\n",
    "        lgr = logging.getLogger(logger_name)\n",
    "        lgr.addHandler(h)\n",
    "        lgr.setLevel(logging.INFO)\n",
    "    \n",
    "    model = load_model(\"anthropic\", audit=True, telemetry=True)\n",
    "    \n",
    "    # Walk the stack\n",
    "    layers = []\n",
    "    layer = model\n",
    "    while hasattr(layer, '_inner'):\n",
    "        layers.append(type(layer).__name__)\n",
    "        layer = layer._inner\n",
    "    layers.append(type(layer).__name__)\n",
    "    print(f\"Stack: {' → '.join(layers)}\")\n",
    "    print()\n",
    "    \n",
    "    response = await model.invoke([\n",
    "        Message(role=\"user\", content=\"Say 'audit works' in exactly those words.\")\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\nResponse: {response.content}\")\n",
    "    print(\"\\nTwo log lines above: one from Telemetry (timing/cost), one from Audit (metadata)\")\n",
    "    \n",
    "    for logger_name in [\"arcllm.modules.audit\", \"arcllm.modules.telemetry\"]:\n",
    "        lgr = logging.getLogger(logger_name)\n",
    "        lgr.removeHandler(h)\n",
    "    \n",
    "    # Close innermost adapter\n",
    "    innermost = model\n",
    "    while hasattr(innermost, '_inner'):\n",
    "        innermost = innermost._inner\n",
    "    await innermost.close()\n",
    "else:\n",
    "    print(\"Skipped — no API key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_key:\n",
    "    clear_cache()\n",
    "    \n",
    "    # Full stack with all modules\n",
    "    h = logging.StreamHandler()\n",
    "    h.setFormatter(logging.Formatter(\"%(levelname)s %(name)s: %(message)s\"))\n",
    "    for logger_name in [\"arcllm.modules.audit\", \"arcllm.modules.telemetry\"]:\n",
    "        lgr = logging.getLogger(logger_name)\n",
    "        lgr.addHandler(h)\n",
    "        lgr.setLevel(logging.INFO)\n",
    "    \n",
    "    model = load_model(\n",
    "        \"anthropic\",\n",
    "        telemetry=True,\n",
    "        audit=True,\n",
    "        retry=True,\n",
    "        rate_limit=True,\n",
    "    )\n",
    "    \n",
    "    layers = []\n",
    "    layer = model\n",
    "    while hasattr(layer, '_inner'):\n",
    "        layers.append(type(layer).__name__)\n",
    "        layer = layer._inner\n",
    "    layers.append(type(layer).__name__)\n",
    "    print(f\"Stack: {' → '.join(layers)}\")\n",
    "    print()\n",
    "    \n",
    "    response = await model.invoke([\n",
    "        Message(role=\"user\", content=\"What color is the sky? One word.\")\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\nResponse: {response.content}\")\n",
    "    \n",
    "    for logger_name in [\"arcllm.modules.audit\", \"arcllm.modules.telemetry\"]:\n",
    "        lgr = logging.getLogger(logger_name)\n",
    "        lgr.removeHandler(h)\n",
    "    \n",
    "    innermost = model\n",
    "    while hasattr(innermost, '_inner'):\n",
    "        innermost = innermost._inner\n",
    "    await innermost.close()\n",
    "else:\n",
    "    print(\"Skipped — no API key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Component | What | Why |\n",
    "|-----------|------|-----|\n",
    "| `AuditModule` | Logs audit metadata per `invoke()` | Federal compliance — every LLM interaction has a trail |\n",
    "| PII-safe default | No raw content logged | NIST 800-53 AU-3: audit without new PII exposure |\n",
    "| `include_messages` | Opt-in message content at DEBUG | Double opt-in for dev/staging environments |\n",
    "| `include_response` | Opt-in response content at DEBUG | Same double opt-in safety |\n",
    "| `_sanitize()` | Escapes `\\n`, `\\r`, `\\t` | Prevents log injection attacks |\n",
    "| `log_structured()` | Shared helper for all modules | DRY, consistent format, `None` omission, level gating |\n",
    "| `validate_log_level()` | Shared validation | DRY between Telemetry and Audit |\n",
    "| `_VALID_CONFIG_KEYS` | Strict key checking | Catches typos at construction time |\n",
    "| Conditional fields | tools_provided, tool_calls | Only appear when relevant — reduces log noise |\n",
    "| Stack position | Between Telemetry and Retry | Logs final result, not intermediate retry attempts |\n",
    "\n",
    "**Config**:\n",
    "```python\n",
    "load_model(\"anthropic\", audit=True)                                  # PII-safe metadata only\n",
    "load_model(\"anthropic\", audit={\"include_messages\": True})            # + message content at DEBUG\n",
    "load_model(\"anthropic\", audit={\"include_response\": True})            # + response content at DEBUG\n",
    "load_model(\"anthropic\", audit={\"log_level\": \"DEBUG\"})                # Custom level\n",
    "load_model(\"anthropic\", audit=False)                                 # Disable\n",
    "```\n",
    "\n",
    "**Log output** (default):\n",
    "```\n",
    "INFO  arcllm.modules.audit: Audit | provider=anthropic model=claude-sonnet-4-20250514\n",
    "  message_count=2 stop_reason=end_turn tools_provided=1 tool_calls=2 content_length=142\n",
    "```\n",
    "\n",
    "**Test count**: 311 passed, 1 skipped (19 audit tests + 5 logging helper tests + 3 registry tests)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}