{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 4: Agentic Tool-Calling Loop\n",
        "\n",
        "This notebook validates ArcLLM's unified interface by running **real API calls** through the Anthropic adapter in a complete agentic tool-calling loop.\n",
        "\n",
        "**What we're testing:**\n",
        "1. Simple text response — does `invoke()` return a properly typed `LLMResponse`?\n",
        "2. Calculator tool loop — can the agent send a tool, execute it, and return the result?\n",
        "3. Search tool loop — same pattern with a canned search tool\n",
        "4. Multi-tool — both tools available, LLM picks which to use\n",
        "\n",
        "**Prerequisites:**\n",
        "- `ANTHROPIC_API_KEY` environment variable set\n",
        "- `pip install -e \".[dev]\"` completed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Verify API key is available\n",
        "assert os.environ.get(\"ANTHROPIC_API_KEY\"), \"Set ANTHROPIC_API_KEY env var first!\"\n",
        "print(\"API key found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from arcllm import (\n",
        "    AnthropicAdapter,\n",
        "    LLMResponse,\n",
        "    Message,\n",
        "    TextBlock,\n",
        "    Tool,\n",
        "    ToolCall,\n",
        "    ToolResultBlock,\n",
        "    ToolUseBlock,\n",
        "    Usage,\n",
        "    load_provider_config,\n",
        ")\n",
        "\n",
        "# Load real Anthropic config\n",
        "config = load_provider_config(\"anthropic\")\n",
        "print(f\"Provider: {config.provider.api_format}\")\n",
        "print(f\"Default model: {config.provider.default_model}\")\n",
        "print(f\"Available models: {list(config.models.keys())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the adapter — uses a cheaper/faster model for testing\n",
        "MODEL = \"claude-haiku-4-5-20251001\"\n",
        "adapter = AnthropicAdapter(config, MODEL)\n",
        "print(f\"Adapter name: {adapter.name}\")\n",
        "print(f\"Model: {adapter._model_name}\")\n",
        "print(f\"Model meta: context_window={adapter._model_meta.context_window}, supports_tools={adapter._model_meta.supports_tools}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Test 1: Simple Text Response\n",
        "\n",
        "The simplest case — send a message, get text back. Validates:\n",
        "- `invoke()` returns `LLMResponse`\n",
        "- `content` is a string\n",
        "- `usage` has token counts\n",
        "- `stop_reason` is `end_turn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [\n",
        "    Message(role=\"user\", content=\"What is 2 + 2? Reply with just the number.\")\n",
        "]\n",
        "\n",
        "response = await adapter.invoke(messages, max_tokens=50)\n",
        "\n",
        "print(f\"Type: {type(response).__name__}\")\n",
        "print(f\"Content: {response.content}\")\n",
        "print(f\"Stop reason: {response.stop_reason}\")\n",
        "print(f\"Usage: in={response.usage.input_tokens}, out={response.usage.output_tokens}, total={response.usage.total_tokens}\")\n",
        "print(f\"Tool calls: {response.tool_calls}\")\n",
        "print(f\"Model: {response.model}\")\n",
        "\n",
        "# Type assertions\n",
        "assert isinstance(response, LLMResponse)\n",
        "assert isinstance(response.content, str)\n",
        "assert response.stop_reason == \"end_turn\"\n",
        "assert isinstance(response.usage, Usage)\n",
        "assert response.usage.total_tokens > 0\n",
        "assert response.tool_calls == []\n",
        "print(\"\\n✓ All assertions passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Test 2: Calculator Tool Loop\n",
        "\n",
        "This is the core agentic pattern:\n",
        "1. Agent sends a math problem with a `calculate` tool available\n",
        "2. LLM responds with `stop_reason=tool_use` and a `ToolCall`\n",
        "3. Agent executes the tool (Python `eval` for simplicity)\n",
        "4. Agent packs the result as `ToolResultBlock` and sends back\n",
        "5. LLM responds with final answer (`stop_reason=end_turn`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the calculator tool\n",
        "calculator_tool = Tool(\n",
        "    name=\"calculate\",\n",
        "    description=\"Evaluate a mathematical expression. Returns the numeric result.\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"expression\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The math expression to evaluate, e.g. '2 + 3 * 4'\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"expression\"]\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"Tool: {calculator_tool.name}\")\n",
        "print(f\"Schema: {json.dumps(calculator_tool.parameters, indent=2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple tool executor\n",
        "def execute_calculate(arguments: dict) -> str:\n",
        "    \"\"\"Execute the calculate tool. Returns result as string.\"\"\"\n",
        "    expr = arguments[\"expression\"]\n",
        "    # Safe eval for basic math only\n",
        "    allowed = set(\"0123456789+-*/.() \")\n",
        "    if not all(c in allowed for c in expr):\n",
        "        return f\"Error: unsafe expression '{expr}'\"\n",
        "    try:\n",
        "        result = eval(expr)  # noqa: S307 — restricted to numeric chars\n",
        "        return str(result)\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Quick test\n",
        "print(execute_calculate({\"expression\": \"2 + 3 * 4\"}))\n",
        "print(execute_calculate({\"expression\": \"(100 - 37) / 9\"}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Turn 1: Agent sends math problem with calculator tool ---\n",
        "\n",
        "messages = [\n",
        "    Message(role=\"system\", content=\"You are a helpful assistant. Use the calculate tool for any math.\"),\n",
        "    Message(role=\"user\", content=\"What is 137 * 42 + 19?\")\n",
        "]\n",
        "\n",
        "response_1 = await adapter.invoke(messages, tools=[calculator_tool], max_tokens=200)\n",
        "\n",
        "print(f\"Stop reason: {response_1.stop_reason}\")\n",
        "print(f\"Content: {response_1.content}\")\n",
        "print(f\"Tool calls: {len(response_1.tool_calls)}\")\n",
        "\n",
        "# Should be a tool call\n",
        "assert response_1.stop_reason == \"tool_use\"\n",
        "assert len(response_1.tool_calls) >= 1\n",
        "\n",
        "tool_call = response_1.tool_calls[0]\n",
        "print(f\"\\nTool call:\")\n",
        "print(f\"  id: {tool_call.id}\")\n",
        "print(f\"  name: {tool_call.name}\")\n",
        "print(f\"  arguments: {tool_call.arguments}\")\n",
        "\n",
        "assert isinstance(tool_call, ToolCall)\n",
        "assert tool_call.name == \"calculate\"\n",
        "assert isinstance(tool_call.arguments, dict)\n",
        "print(\"\\n✓ Turn 1 assertions passed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Turn 2: Agent executes tool and sends result back ---\n",
        "\n",
        "# Execute the tool\n",
        "result = execute_calculate(tool_call.arguments)\n",
        "print(f\"Tool result: {result}\")\n",
        "\n",
        "# Build the assistant message (what the LLM said) and tool result message\n",
        "# The assistant's response becomes a message with ToolUseBlock content\n",
        "assistant_content = []\n",
        "if response_1.content:\n",
        "    assistant_content.append(TextBlock(text=response_1.content))\n",
        "for tc in response_1.tool_calls:\n",
        "    assistant_content.append(ToolUseBlock(id=tc.id, name=tc.name, arguments=tc.arguments))\n",
        "\n",
        "messages.append(Message(role=\"assistant\", content=assistant_content))\n",
        "messages.append(Message(\n",
        "    role=\"tool\",\n",
        "    content=[ToolResultBlock(tool_use_id=tool_call.id, content=result)]\n",
        "))\n",
        "\n",
        "print(f\"\\nMessages in conversation: {len(messages)}\")\n",
        "for i, m in enumerate(messages):\n",
        "    content_preview = m.content if isinstance(m.content, str) else f\"[{len(m.content)} blocks]\"\n",
        "    print(f\"  {i}: role={m.role}, content={content_preview}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Turn 2 continued: Send the tool result back to the LLM ---\n",
        "\n",
        "response_2 = await adapter.invoke(messages, tools=[calculator_tool], max_tokens=200)\n",
        "\n",
        "print(f\"Stop reason: {response_2.stop_reason}\")\n",
        "print(f\"Content: {response_2.content}\")\n",
        "print(f\"Tool calls: {response_2.tool_calls}\")\n",
        "print(f\"Usage: in={response_2.usage.input_tokens}, out={response_2.usage.output_tokens}\")\n",
        "\n",
        "# Should be a final text response\n",
        "assert response_2.stop_reason == \"end_turn\"\n",
        "assert response_2.content is not None\n",
        "assert response_2.tool_calls == []\n",
        "\n",
        "# The answer should contain 5773 (137 * 42 + 19 = 5773)\n",
        "assert \"5773\" in response_2.content or \"5,773\" in response_2.content, f\"Expected 5773 in response: {response_2.content}\"\n",
        "print(\"\\n✓ Calculator loop complete — all assertions passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Test 3: Search Tool Loop\n",
        "\n",
        "Same agentic pattern but with a search tool that returns canned results.\n",
        "Validates that string content in `ToolResultBlock` works correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the search tool\n",
        "search_tool = Tool(\n",
        "    name=\"web_search\",\n",
        "    description=\"Search the web for current information. Returns relevant search results.\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"query\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The search query\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"query\"]\n",
        "    }\n",
        ")\n",
        "\n",
        "# Canned search results\n",
        "SEARCH_RESULTS = {\n",
        "    \"default\": \"Search result: According to recent data, the answer you're looking for is available. Here are the key findings: The topic has been extensively studied with conclusive results.\"\n",
        "}\n",
        "\n",
        "def execute_search(arguments: dict) -> str:\n",
        "    \"\"\"Execute the search tool with canned results.\"\"\"\n",
        "    query = arguments.get(\"query\", \"\")\n",
        "    return f\"Search results for '{query}': {SEARCH_RESULTS['default']}\"\n",
        "\n",
        "print(f\"Tool: {search_tool.name}\")\n",
        "print(f\"Test: {execute_search({'query': 'test query'})}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Search loop: Turn 1 ---\n",
        "\n",
        "search_messages = [\n",
        "    Message(role=\"user\", content=\"Search for information about the Eiffel Tower's height and tell me what you find.\")\n",
        "]\n",
        "\n",
        "search_response_1 = await adapter.invoke(search_messages, tools=[search_tool], max_tokens=300)\n",
        "\n",
        "print(f\"Stop reason: {search_response_1.stop_reason}\")\n",
        "print(f\"Tool calls: {len(search_response_1.tool_calls)}\")\n",
        "\n",
        "assert search_response_1.stop_reason == \"tool_use\"\n",
        "assert len(search_response_1.tool_calls) >= 1\n",
        "\n",
        "search_tc = search_response_1.tool_calls[0]\n",
        "print(f\"Tool: {search_tc.name}, args: {search_tc.arguments}\")\n",
        "assert search_tc.name == \"web_search\"\n",
        "\n",
        "# Execute and return\n",
        "search_result = execute_search(search_tc.arguments)\n",
        "print(f\"Result: {search_result[:100]}...\")\n",
        "\n",
        "# Build turn 2 messages\n",
        "search_assistant_content = []\n",
        "if search_response_1.content:\n",
        "    search_assistant_content.append(TextBlock(text=search_response_1.content))\n",
        "for tc in search_response_1.tool_calls:\n",
        "    search_assistant_content.append(ToolUseBlock(id=tc.id, name=tc.name, arguments=tc.arguments))\n",
        "\n",
        "search_messages.append(Message(role=\"assistant\", content=search_assistant_content))\n",
        "search_messages.append(Message(\n",
        "    role=\"tool\",\n",
        "    content=[ToolResultBlock(tool_use_id=search_tc.id, content=search_result)]\n",
        "))\n",
        "\n",
        "search_response_2 = await adapter.invoke(search_messages, tools=[search_tool], max_tokens=300)\n",
        "\n",
        "print(f\"\\nFinal stop reason: {search_response_2.stop_reason}\")\n",
        "print(f\"Final content: {search_response_2.content}\")\n",
        "\n",
        "assert search_response_2.stop_reason == \"end_turn\"\n",
        "assert search_response_2.content is not None\n",
        "print(\"\\n✓ Search loop complete — all assertions passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Test 4: Multi-Tool (Both Available)\n",
        "\n",
        "Give the LLM both tools and ask a question that could use either.\n",
        "Validates that the adapter handles tool selection correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tool dispatcher\n",
        "TOOL_EXECUTORS = {\n",
        "    \"calculate\": execute_calculate,\n",
        "    \"web_search\": execute_search,\n",
        "}\n",
        "\n",
        "async def run_agentic_loop(\n",
        "    adapter: AnthropicAdapter,\n",
        "    messages: list[Message],\n",
        "    tools: list[Tool],\n",
        "    max_turns: int = 5,\n",
        ") -> LLMResponse:\n",
        "    \"\"\"Run a complete agentic tool-calling loop.\"\"\"\n",
        "    for turn in range(max_turns):\n",
        "        response = await adapter.invoke(messages, tools=tools, max_tokens=500)\n",
        "        print(f\"  Turn {turn + 1}: stop_reason={response.stop_reason}, tool_calls={len(response.tool_calls)}\")\n",
        "        \n",
        "        if response.stop_reason != \"tool_use\":\n",
        "            return response\n",
        "        \n",
        "        # Build assistant message with tool use blocks\n",
        "        assistant_content = []\n",
        "        if response.content:\n",
        "            assistant_content.append(TextBlock(text=response.content))\n",
        "        for tc in response.tool_calls:\n",
        "            assistant_content.append(ToolUseBlock(id=tc.id, name=tc.name, arguments=tc.arguments))\n",
        "        messages.append(Message(role=\"assistant\", content=assistant_content))\n",
        "        \n",
        "        # Execute each tool and pack results\n",
        "        tool_results = []\n",
        "        for tc in response.tool_calls:\n",
        "            executor = TOOL_EXECUTORS.get(tc.name)\n",
        "            if executor:\n",
        "                result = executor(tc.arguments)\n",
        "                print(f\"    Tool '{tc.name}': {result[:80]}\")\n",
        "            else:\n",
        "                result = f\"Error: unknown tool '{tc.name}'\"\n",
        "            tool_results.append(ToolResultBlock(tool_use_id=tc.id, content=result))\n",
        "        \n",
        "        messages.append(Message(role=\"tool\", content=tool_results))\n",
        "    \n",
        "    raise RuntimeError(f\"Agentic loop did not complete in {max_turns} turns\")\n",
        "\n",
        "print(\"Agentic loop helper defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multi-tool test: ask something that needs calculation\n",
        "multi_messages = [\n",
        "    Message(\n",
        "        role=\"system\",\n",
        "        content=\"You have access to a calculator and web search. Use the appropriate tool.\"\n",
        "    ),\n",
        "    Message(\n",
        "        role=\"user\",\n",
        "        content=\"What is 256 * 789? Use the calculate tool.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"Running multi-tool agentic loop...\")\n",
        "final_response = await run_agentic_loop(adapter, multi_messages, [calculator_tool, search_tool])\n",
        "\n",
        "print(f\"\\nFinal response:\")\n",
        "print(f\"  Content: {final_response.content}\")\n",
        "print(f\"  Stop reason: {final_response.stop_reason}\")\n",
        "print(f\"  Usage: in={final_response.usage.input_tokens}, out={final_response.usage.output_tokens}\")\n",
        "\n",
        "assert final_response.stop_reason == \"end_turn\"\n",
        "assert final_response.content is not None\n",
        "# 256 * 789 = 201984\n",
        "assert \"201984\" in final_response.content or \"201,984\" in final_response.content, f\"Expected 201984 in: {final_response.content}\"\n",
        "print(\"\\n✓ Multi-tool loop complete — all assertions passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Summary & Type Verification\n",
        "\n",
        "Verify that every object in the loop is correctly typed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect all responses for type checking\n",
        "all_responses = [response, response_2, search_response_1, search_response_2, final_response]\n",
        "\n",
        "print(\"Type verification across all responses:\")\n",
        "for i, r in enumerate(all_responses):\n",
        "    assert isinstance(r, LLMResponse), f\"Response {i} is not LLMResponse\"\n",
        "    assert isinstance(r.usage, Usage), f\"Response {i} usage is not Usage\"\n",
        "    assert isinstance(r.model, str), f\"Response {i} model is not str\"\n",
        "    assert isinstance(r.stop_reason, str), f\"Response {i} stop_reason is not str\"\n",
        "    assert isinstance(r.tool_calls, list), f\"Response {i} tool_calls is not list\"\n",
        "    for tc in r.tool_calls:\n",
        "        assert isinstance(tc, ToolCall), f\"Tool call is not ToolCall\"\n",
        "        assert isinstance(tc.arguments, dict), f\"Tool call arguments is not dict\"\n",
        "    print(f\"  Response {i}: ✓ (stop={r.stop_reason}, tools={len(r.tool_calls)}, tokens={r.usage.total_tokens})\")\n",
        "\n",
        "print(f\"\\n✓ All {len(all_responses)} responses are correctly typed\")\n",
        "print(f\"\\nTotal tokens used: {sum(r.usage.total_tokens for r in all_responses)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean up\n",
        "await adapter.close()\n",
        "print(\"Adapter closed. Step 4 complete!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
